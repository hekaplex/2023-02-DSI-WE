{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not install packages due to an OSError: [WinError 5] Access is denied: 'C:\\\\Users\\\\dolly\\\\AppData\\\\Local\\\\r-miniconda\\\\envs\\\\datascience-pro-env\\\\Lib\\\\site-packages\\\\~2ipy.libs\\\\libopenblas-802f9ed1179cb9c9b03d67ff79f48187.dll'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.2.2-cp311-cp311-win_amd64.whl (8.3 MB)\n",
      "Collecting numpy>=1.17.3\n",
      "  Using cached numpy-1.24.3-cp311-cp311-win_amd64.whl (14.8 MB)\n",
      "Collecting scipy>=1.3.2\n",
      "  Using cached scipy-1.10.1-cp311-cp311-win_amd64.whl (42.2 MB)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)\n",
      "Collecting threadpoolctl>=2.0.0\n",
      "  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: threadpoolctl, numpy, joblib, scipy, scikit-learn\n",
      "  Attempting uninstall: threadpoolctl\n",
      "    Found existing installation: threadpoolctl 3.1.0\n",
      "    Uninstalling threadpoolctl-3.1.0:\n",
      "      Successfully uninstalled threadpoolctl-3.1.0\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.24.3\n",
      "    Uninstalling numpy-1.24.3:\n",
      "      Successfully uninstalled numpy-1.24.3\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.2.0\n",
      "    Uninstalling joblib-1.2.0:\n",
      "      Successfully uninstalled joblib-1.2.0\n",
      "  Attempting uninstall: scipy\n",
      "    Found existing installation: scipy 1.10.1\n",
      "    Uninstalling scipy-1.10.1:\n",
      "      Successfully uninstalled scipy-1.10.1\n"
     ]
    }
   ],
   "source": [
    "# !pip install openpyxl  \n",
    "import os\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pylab as plt\n",
    "#import matplotlib.pyplot as plt \n",
    "plt.style.use('fivethirtyeight') \n",
    "import seaborn as sns \n",
    "%matplotlib inline\n",
    "\n",
    "df1 = pd.read_csv(\"Daignosed_Ob_df01.csv\" )\n",
    "df2 = pd.read_csv(\"Diagnosed_Db_df01.csv\" )\n",
    "df3 = pd.read_csv(\"Diagnosed_HBp_df01.csv\" )\n",
    "df4 = pd.read_csv(\"Diagnosed_Hc_df01.csv\" )\n",
    "df5 = pd.read_csv(\"Diagnosed_Hd_df01.csv\" )\n",
    "df6 = pd.read_csv(\"Diagnosed_STr_df01.csv\" )\n",
    "\n",
    "\n",
    "%pip install scikit-learn  --upgrade --force\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraies\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "%metplotlib inline \n",
    "\n",
    " \n",
    "df1 = pd.read_csv(\"Daignosed_Ob_df01.csv\" )\n",
    "df2 = pd.read_csv(\"Diagnosed_Db_df01.csv\" )\n",
    "df3 = pd.read_csv(\"Diagnosed_HBp_df01.csv\" )\n",
    "df4 = pd.read_csv(\"Diagnosed_Hc_df01.csv\" )\n",
    "df5 = pd.read_csv(\"Diagnosed_Hd_df01.csv\" )\n",
    "df6 = pd.read_csv(\"Diagnosed_STr_df01.csv\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "#%pip install scikit-learn  --upgrade --force\n",
    "%pip install --upgrade scikit-learn==0.23.0\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6 = df6.drop(columns = ['StkCity','StkLowFid', 'StkHighFid', 'StkMeanByUS', 'StkRelByUS',\n",
    "       'Stk_Lat', 'Stk_Log'])\n",
    "df6 = df6.rename(columns={'StkMean':'Target'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2, df3, df4, df5, df6], axis=1)\n",
    "df.head().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df6.info\n",
    "#df6.head()\n",
    "#df6\n",
    "#df6.columns\n",
    "#df6.describe()\n",
    "#df6.to_numeric(df6['StkMean'])\n",
    "#df6.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.youtube.com/watch?v=wzN1UyfRSWI&t=444s\n",
    "df = pd.concat([df1, df2, df3, df4, df5, df6], axis=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Index:  \", df.index)\n",
    "print(\"Columns:\", df.columns)\n",
    "print(\"Size:   \", df.size)\n",
    "print(\"Shape:  \", df.shape)\n",
    "#df.isna().sum()\n",
    "#df.isna().sum()\n",
    "#df.head().T\n",
    "#df.head()\n",
    "#df.info()\n",
    "#df.shape \n",
    "#df.describe().T # run a quick stat \n",
    "#df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Heatmap\n",
    "# Summary: Distribution of all the factors from cities in the US. \n",
    "plt.title('Distribution of all 5 diagnoses by the states and its cities')\n",
    "df_corr = df[['ObMean',  'DbMean', 'HBpMean','HcMean', 'HdMean']].corr()\n",
    "sns.heatmap(df_corr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dividing the dataset into independent and dependent features.\n",
    "X=df.iloc[:, :-1] # Independent features.\n",
    "y=df.iloc[:, -1]  # dependent features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod types of model to use.\n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade scikit-learn==0.23.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression ()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prdict = model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Linear Regession.\n",
    "#linear_reg =  LinearRegression() # the model\n",
    "#mse=cross_val_score(linear_reg,X,y,scoring='neg_mean_squared_err',cv=5)\n",
    "#print(mse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
