{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Science Project - Machine Leaning.\n",
    "Predicating Stroke Population based on 5 different factors.\n",
    "\n",
    "Factors:Stroke as the target.\n",
    "Diabetes, Heart Disease, High Blood Pressure, High Cholesterol, and Obesity.\n",
    "\n",
    "####### Data provided by https://data.cdc.gov/\n",
    "Dataset Files:  Diabetes.cvs\n",
    "Data Measure: 500 Cities: Diagnosed diabetes among adults aged >=18 years\n",
    "\n",
    "Capstone: \n",
    "Y = (Predicted) Stroke. \n",
    "X = (Multiple Factors) Diabetes, Heart Dissease, High Blood Pressure, High Cholesterol, and Obesity \n",
    "\n",
    "ML Algorithms = Will be focusing on supervised (multiple linear regression) numeric values.\n",
    "\n",
    "Data type/Metrix:\n",
    "Quantitative/Nemerical Data (Continuous)\n",
    "Discrete data - Data with final set of vlaues which can be categorized.\n",
    "Continuous - take any numerical value within a range. \n",
    "-=============================================\n",
    "Intructions:\n",
    "-=============================================\n",
    "1.\tfilter by, StateCity and Age-adjusted prevalence\n",
    "2.\tcreate three data frames based on distinct GeographicLevel\n",
    "3.\tJoin or copy the US row to materialize the ratios for US\n",
    "4.\tJoin the city data by cityFIPS to the tractFIPS rows to calculate their ratios\n",
    "5.\tSplit the geo into (lat , long)\n",
    "6.\tjoin all features into one dataframe\n",
    "7.\tjoin one filtered frame of stroke target before \n",
    "8.\tmodeling\n",
    "\n",
    "\n",
    "-=========================================\n",
    "Data Wranging: \n",
    "**** Instruction #1 and #5\n",
    "-=========================================\n",
    "1. Drop all unwanted columns.\n",
    "   Keeping and sort in the following orders: \n",
    "   Short_Question_Text,\tStateAbbr,\tCityName,\tData_Value,\tLow_Confidence_Limit,\tHigh_Confidence_Limit,\tGeoLocation,\n",
    "\n",
    "\n",
    "2. Sort data (Asce order)\n",
    " - by StateAbbr, StateDesc, CityName,\n",
    " - Data_Value_Type(order by Age-adjusted prevalence) assigned to  DB_New_df.\n",
    "3. DB_New_df merge 3column names and create a new column called Db_StCity.\n",
    "  Db_StCity = Short_Question_Text + StateAbbr + CityName.  \n",
    "4. Split the GeoLocation into:\n",
    "    Latitude = New column [DB_Latitude ]\n",
    "                42.536457 \n",
    "    Longitude = New column [DB_Longitude ]\n",
    "   \t            -70.985786\n",
    "5. Format: missing values or removing unwanted records(dup), rearrange columns, change data type...ect.\n",
    "  ** Remove null/blank in the column with str. before merging rows.\n",
    "  ** Check for inconsist names in the rows. \n",
    "  ** For example:  the state name is TX but the cell name is \"United States\".\n",
    "  *** Check for Geolocation, it \"Blank\" sometimes.\n",
    "\n",
    "6. Write to a new file, \" NEW_Diabetes.csv\"\n",
    "7. Repeat the same process for all five files.\n",
    "   -======================================\n",
    "8. Run stat and Data Calculations:\n",
    "9. Merge data frames.\n",
    "\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# importing the libraies\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import math \n",
    "#%metplotlib inline #\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn  --upgrade --force\n",
    "#from sklearn.linear_model import LinearRegression\n",
    "#from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading, loading  datasets. \n",
    "\n",
    "df = pd.read_csv(\"500_Cities_Diagnosed_diabetes.csv\" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head().T\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unwanted columns.\n",
    "New_df = df.drop(columns=['Year','StateDesc', 'DataSource', 'Category', 'UniqueID', \\\n",
    "    'Data_Value_Unit','DataValueTypeID',  'Measure', 'Data_Value_Footnote_Symbol', \\\n",
    "    'Data_Value_Footnote', 'CategoryID', 'MeasureId', 'Short_Question_Text'])\n",
    "\n",
    "#Rename columns\n",
    "New_df = New_df.rename(columns={'StateAbbr':'Db_States', 'CityName':'Db_City',\\ \n",
    "    'GeographicLevel':'Db_Geoloc', 'Data_Value_Type':'Db_AgeAdj_preval', \\\n",
    "    'Data_Value':'Db_Mean_Pop', 'Low_Confidence_Limit':'Db_Low_Conf', \\\n",
    "    'High_Confidence_Limit':'Db_High_Conf', 'PopulationCount':'Db_Population' })\n",
    "\n",
    "#Change data type:\n",
    "# removing the \",\" from the PopCountByMM values and replace it with nothing than change it from object type to int. \n",
    "New_df[\"Db_Population\"] = New_df[\"Db_Population\"].str.replace(',','').astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Db_States', 'Db_City', 'Db_Geoloc', 'Db_AgeAdj_preval', 'Db_Mean_Pop',\n",
       "       'Db_Low_Conf', 'Db_High_Conf', 'Db_Population', 'GeoLocation',\n",
       "       'CityFIPS', 'TractFIPS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "New_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "New_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New_df.sort_values([\"States\"])\n",
    "New_df.sort_values([\"Db_States\", \"City\"], ascending=[1,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for NaN/NULL and count them.\n",
    "#New_df.isna().sum()\n",
    "# Checking for NULL, NaN values\n",
    "#New_df.query(\"Pre_Diabetic.isna()\")\n",
    "\n",
    "#Dropping NaN values. Make sure to select every columns in the dataframe.\n",
    "New_df[[ 'States', 'City', 'AgeAdj_Prevalence', 'Diabetic', 'Low_Risk', 'Pre_Diabetic',\n",
    "'Pop_Count' ]].dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Double check on the NaN\n",
    "New_df.query(\"Diabetic.isna()\")\n",
    "New_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Double check on the NaN NULL\n",
    "New_df.isna().sum()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#New_df.sort_values([\"States\"])\n",
    "New_df.sort_values([\"States\", \"City\"], ascending=[1,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to a new file.\n",
    "df_diab_01 = New_df.query('`AgeAdj_Prevalence` == \"Age-adjusted prevalence\"')\n",
    "df_diab_01\n",
    "\n",
    "# This code will do the same\n",
    "#df_diab_01.loc[df_diab_01.duplicated(subset=['States'])]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count dup values.\n",
    "# df_diab_01.loc[df_diab_01.duplicated(subset=['States'])]\n",
    "df_diab_01.loc[df_diab_01.duplicated(subset=['States'])].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify vales for TX/city based on \"Age-adjusted prevalence\"\n",
    "df_diab_01 = df_diab_01.query('`States` == \"TX\"')\n",
    "df_diab_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concat State and City name into a NEW column called StateAndCity:\n",
    "df_diab_01 ['StateAndCity'] = df_diab_01['States'] + '_' + df_diab_01['City']\n",
    "df_diab_01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DROPPING the states and city columns after concat:\n",
    "df_diab_01 = df_diab_01.drop(columns=['States','City' ])\n",
    "df_diab_01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diab_01.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reorganize the columns\n",
    "#Create a new list in the order that you want.\n",
    "New_cols = ['StateAndCity','Diabetic', 'Pre_Diabetic', 'Low_Risk', 'Pop_Count']\n",
    "df_diab_01 = df_diab_01[New_cols]\n",
    "df_diab_01\n",
    "\n",
    "df_diab_01.to_csv(\"New_Diabetes_X01.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diab_01.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
